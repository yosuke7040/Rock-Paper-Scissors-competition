# Rock-Paper-Scissors

じゃんけんコンペ

## Basics
**Overview(DeepL)**

グー、パー、チョキ（時々 roshambo と呼ばれる）は、遊び場の意見の相違を解決したり、誰が道路の旅で前の座席に乗るために取得を決定するための定番となっています。ゲームはシンプルで、力のバランスが取れています。3つの選択肢があり、それぞれが他の2人に勝つか負けるかを選択できます。一連の本当にランダムなゲームでは、それぞれのプレイヤーが勝ったり負けたり、ゲームの大体3分の1を引き分けたりします。しかし、人間は本当にランダムではないので、AIに楽しい機会を与えてくれます。

研究では、グー、パー、チョキAIが一貫して人間の対戦相手を打ち負かすことができることが示されています。過去のゲームをインプットとして、それはパターンを研究してプレイヤーの傾向を理解する。しかし、単純な「ベスト・オブ・3」のゲームを「ベスト・オブ・1000」に拡張するとどうなるのだろうか。人工知能はどれだけのパフォーマンスを発揮できるのでしょうか？

このシミュレーション大会では、この古典的なゲームを何度もラウンドを重ねて対戦するAIを作成します。あなたのAIが負けるよりも、あなたのAIが勝つパターンを見つけることができるでしょうか？マッチがランダムではないエージェントを含む場合、ランダムなプレイヤーを大幅に上回ることが可能です。強いAIは、予測可能なAIに一貫して勝つことができる。

この問題は、機械学習、人工知能、データ圧縮の分野では基本的な問題です。人間の心理学や階層的時間記憶への応用の可能性さえある。手を温めて、この課題でRock, Paper, Scissorsの準備をしましょう。

**Evaluation**
毎日、あなたのチームは最大5人のエージェント（ボット）を大会に提出することができます。各エージェントは、同じようなスキル評価を持つ他のボットとのエピソード（ゲーム）で対戦します。時間が経つにつれて、スキルの評価は、勝てば上がる、負ければ下がるようになります。提出されたボットは、大会終了までゲームをプレイし続けます。リーダーボードには、最高得点を獲得したボットのみが表示されますが、提出物ページではすべての提出物の進捗状況を確認することができます。

各提出物には推定スキル評価があり、ガウシアンN(μ,σ2)でモデル化されており、μは推定スキル、σは推定スキルの不確実性を表し、時間の経過とともに減少します。

提出物をアップロードすると、最初に検証エピソードを再生し、提出物が正しく動作するかどうかを確認します。エピソードが失敗した場合、提出物はエラーとしてマークされます。そうでない場合は、サブミッションをμ0=600で初期化し、継続的な評価のためにすべてのサブミッションのプールに参加します。

すべての提出物のプールからエピソードを繰り返し実行し、公正に一致するように類似の評価を持つ提出物を選択します。1日に8エピソードを実行することを目標としていますが、より早くフィードバックを得られるように、最新の投稿エピソードには若干の追加料金を加えています。

エピソードが終了すると、そのエピソードに含まれるすべての提出物の評価が更新されます。あるサブミッションが勝った場合は、そのサブミッションのμ値を増加させ、相手のμ値を減少させます。更新は、以前のμ値に基づく期待される結果からの偏差と、各提出物の不確実性σとの相対的な大きさを持つことになります。また、結果によって得られる情報量に応じてσの項を減らします。あなたのボットがエピソードに勝ったり負けたりするスコアは、スキル評価の更新には影響しません。

投稿締め切り時に、追加投稿はロックされます。エピソードを継続して実行するために、さらに1週間が割り当てられます。この週の終了時に、リーダーボードは最終的なものとなります。

www.DeepL.com/Translator（無料版）で翻訳しました。

**Data**
|id|symbol|
|--|------|
|0|rock|
|1|paper|
|2|scissors|

## Discussion
|no|title|content|url|
|--|--|--|--|

## Log
### 20201101
 - join
 - とりあえずたわらさんのノートブックコピペで出してみる[url](https://www.kaggle.com/ttahara/rps-simple-baseline)
 - sub_nb_001
  - score:612.5
 - 息抜きがてらagent作っていこ
 - 1000回バトル
  - 予測モデルを作る？でも1秒以内に何出すかを決めないといけない
   - .pyを提出するから相手の出したものを読み取るとかじゃない？
 - じゃんけんのシミュレーションして比較できるnotebook[url](https://www.kaggle.com/ihelon/rock-paper-scissors-agents-comparison)
  - agentが何してるかよくわからない
 - 用意してくれてる関数[url](https://github.com/Kaggle/kaggle-environments/blob/master/kaggle_environments/envs/rps/agents.py)
  - 相手がランダムで出してくるレート帯ならstatisticalでカウントして一番出現率の少ない回数に勝つようだすとか
    - もしかしてこれ？[url](https://www.kaggle.com/alexandersamarin/decision-tree-classifier?scriptVersionId=46574034)
    - それを相手がしてるとしてそれに対して勝つようにする？メタゲーム・・・
     - ↑これだとランダムに負けないか？
 - ObservationとConfigurationの[url](https://github.com/Kaggle/kaggle-environments/blob/master/kaggle_environments/envs/rps/helpers.py)


### 20201116
 - とりあえずall ぐー、チョキ、パーの３種類のagentをsub
 - 公開notebookにある戦術として
 |tactics name|content|
 |------------|-------|
 |Hit The Last Own Action|自分が最後に出した行動に対して勝つものを出す（hostのサンプルが相手の出した行動を次の自分の行動にするため）|
 |all rock|全部ぐー|
 |all paper|全部パー|
 |all scissors|全部チョキ|
 |Copy Opponent|相手の最後の行動を真似して出す|
 |Reactionary|相手が最後に出した行動に対して勝つものを出す|
 |Counter Reactionary||
 |Statistical||
 |Nash Equilibrium||
 |Markov Agent||
 |Memory Patterns||
 |Multi Armed Bandit||
 |Opponent Transition Matrix||
 |Decision Tree Classifier||
 |Statistical Prediction||
 
### 202011--
 - まずソース解読しないと書けないわ
 
